#### 性能优化  
大致讨论内容：怎么定义和描述性能问题，可能出现的归因，处理策略，实操怎么排查     

#### 定义性能问题：
1. 最底层是对CPU，GPU，IO，内存等资源的异常占用
2. 在此之上有一些量化指标，fps，tpf(time per frame)，dc，内存，ping占用情况
3. 常见描述就是掉帧(一段时间内总体上述指标的异常)，或者卡顿(突发的短促指标异常)  

#### 性能问题分类枚举和对应策略：
- 枚举思路：
  1. 整个计算机体系来说：数据(规范化)+处理(CPU，GPU，Men，IO角度)
  2. 数据资产环节处理一般是规范化，规范化的范围：UI，模型，材质纹理，粒子，动画，物理，脚本也可以看作数据资产之一也有编码规范
  3. 数据加工类型，各种策略的一般优化模式：增加(算力，资源)， 减少规模， 减少单元消耗(已经减少规模后的遍历单个)， 缓存(即使缓存)， 预加载(离线缓存)
  
  - 数据资产规范化环节(预处理+定标准+砍精度)(UMPAP)：
    1. UI：合图(图集)，节点控制逻辑层级([cocoscreator-UI-Drawcall优化相关](../engine/cocoscreator/性能优化.md#))
    2. 模型：网格合并，面数标准(3k，实际2w)，顶点标准(3k，实际是2w)，渲染DC标准(目前总400左右)，Lod分级开来，数据精度压缩
    3. 纹理：通道压缩，mipmap，[POT❓](https://www.zhihu.com/question/376921536)，[纹理压缩❓](https://zhuanlan.zhihu.com/p/237940807)  
    4. 粒子：发射器数量限制，关联材质限制，粒子同时还是上述内容的组合，对上述内容的规范化也成立
    5. 动画：骨骼点数量限制，插值方式精度限制
    6. 物理：碰撞检测精度(没用上)，射线检测精度控制(级联否，检测对象规模)
   
  - 脚本逻辑编写规范化：
    1. 字符串+和遍历操作
    2. py2中的range和xrange
    3. 涉及到头插的不适合用list得用deque
   
  - CPU相关：
    1. 增加算力：启用多线程，可并行化的部分比如资产中的粒子和动画，业务的寻路等搜索，进度展示相关逻辑
    2. 减少规模：控制遍历规模，寻路为例子条件剪枝，场景对象直接场景管理/遮罩剔除剪枝
    3. 遍历内的单位对象更新次数减少：高蚝操作小心(pow等数学运算), 限制更新次数(一些后台的监听动作，比如全图刷新频率，gc频率)，开启异步
    4. 缓存数据对象：运算逻辑中重复使用的又有搜索的进行缓存复用(寻路version，鼠标指针下状态更新)，对象的高频创建销毁的用对象池
    5. 预加载：有一些逻辑导致时候短时间加载压力比较大，可以通过在合适的时机比如一些转场界面，游戏开始场景跳转等预加载
       > 战场模型预加载了，复杂魔法特效在游戏中释放才会，需要统计角色关联的特效在入场也加载所有可能的特效，防止预加载过大和确实

  - 渲染相关(GPU)：
    流水线模式，管线的任何一环出问题都会导致性能问题，同时关注DC
    1. vs阶段：(增)合批渲染(网格合并，分离线，静态(Unity中编辑，相对有unity是静态)和动态)，(减)模型减面
    2. fs阶段：(增)合理使用MASS，(减)合理使用各种测试(aplha_blend会导致关深度测试,导致片元逻辑变多)
    3. shadow：选合适的模型，贴图，proj(❓), shadowMap
    4. shader: [fs中的if分支❓](https://blog.csdn.net/js0907/article/details/119462842)，浮点数精度，不同的shader模型(逻辑在fs插值前的vs空间还是在插值后的fs空间)
    5. 利用GPU的并行能力：ComputeShader
    6. 材质影响合批(dc): [合批❓](https://zhuanlan.zhihu.com/p/356211912)

  - Men:  
    1. 主要是频繁创建删除导致的内存碎片，碎片带来寻址的变慢和GC问题
       > 对象池思路，直接开辟一块内存并且专用为某些类的初始化池，减少创建销毁的时间开销，也减少内存碎片的创造机会
       > GC的时候如果规模太大可能会卡顿
    2. 提高cash命中率：
       > 使目标内存分布更加紧凑，提高命中cash的几率
       > ECS的提速(局部性原理)，SOA转为AOS(结构体数组转为数组来模拟结构体)  
    2. 内存泄漏
       > 内存泄漏导致内存异常增长，占用太多会导致性能下降(workbench,memory_profile库统计)
       > 内存泄漏可能导致闪退，超过计算机寻址上限  
   
  - IO：  
    短时间的大量IO请求  
    1. 比如加载资源  
       > 压缩资源：纹理压缩格式，模型缩小规模
       > 分帧但并不会减少耗时，只是优化体验
       > 异步加载：IO类请求对于异步是有用的，避免占用主线程
       > 直接将文件映射到内存：boost::iostreams::mapped_file_source file("data.bin")(❓不会)
    2. 和网络请求(❓不会)
       
  - 更底层的一些：
    1. 切换平台：python迁移到c+
    2. SIMD(❓不会)
  
#### 优化实例：
  - UI
    1. 复用滚动框（对象池）

  - 地图相关：
    - 生成  
      1. 冗余循环削减，生成过程多个环节数据有依赖，不要让每个环节重新推演得到数据而服用前面的结果：地形轮廓，不同类型的tile分布等
      2. 限制迭代规模：寻路的时候尽可能的加限制条件，比如限制在Zone内，Hex集合内，按某种state的Tile集合
      3. 高耗时环节向c层的迁移：barr匹配为了随机效果有一定的匹配算法（任意点开始广搜开，按资源尺寸优先度和候选范围面积排序），需要有大量迭代操作，但与生成环节相对隔离依赖小
      4. 整体策略：数据烘焙，剥离玩家依赖：
         > 比如原始生成逻辑会依赖模板配置+玩家输入(比如对应的种族，分配到玩家的区域会根据种族决定地形)，这个时候让生成过程不依赖这个种族设定，地形可以采取类似占位符的形式，走完生成流程后在分配对应的区域给到玩家的配置用玩家选择的配置来二次更新最终的输出数据  
         > 数据规模300*300约等于100k，一个图层+单元大概2Byte所以一张图200k，1MB5张，100M500张，维护的时候更新地图  
      5. 整体策略，分级思想：主城点之间的全联通，全图道具之间的全联通可达，不要直接在Tile进行寻路保证，而是在Hex层级上保证联通，Hex内与锚点联通，然后小规模的Hex联通性代替大规模的Tile联通
      6. 增加算力，分块多线程生成：
         > 地图生成环节每个Zone内的计算比如随机联通分支
         > 内轮廓随机化
         > 资源分配的时候分配公式是按Zone来的
         > MultiProcess/py的假多线程(❓练手)
      
    - 渲染
      1. 用自衔接的纹理平铺，若干张1024*1024资源即可实现不重复的纹理效果  
      2. TileMap的优化：用一个节点代替暴力Tile集合，传入TileMap数据到Shader里面坐标换算+Mask绘制涂层，按地形分层后叠加，剪掉的是脚本节点，引擎对象，管线fs之前顶点规模
      3. 四叉树管理视野内（实际更大）的单元规模，视野外的卸载模型（因为视野较大，并不需要严格检测模型的aabb，直接用锚点位置都可以，四叉树原理❓）
    
    - 更新
      1. 分级思想，减小寻路过程的(准备)数据更新规模：固定数据+动态数据  
         > 寻路的时候经常会受业务影响，寻路范围动态变化，需要消耗算力算这个范围，比如水陆区分，动态阻挡变化位置  
         > 每次都要根据不同的业务计算寻路规模tile比较费时也不好组织逻辑   
         > 根据更新频次将地形分为固定数据和动态数据，动态阻挡这种会经常变化，但是更新范围不多  
         > 静态阻挡用mask来进行筛选跳过  
         > 复用地图状态数据不用每次都组织一遍(减少遍历规模)  
   
      2. 降低刷新频率：  
         > AI或者其他玩家的移动需要刷新地图(而且加了监听可能被自动高频触发)  
         > 每次寻路都是一个全新的正确结果，将刷新频率从实时刷新降为0.1s一刷不影响操作  
 
       3. 迁移C平台，降低单次耗时  
         
       4. 单点多次寻路改为单点多目标全图寻路，缓存寻路结果，与地图状态有关（队友，ai），与自己的位置状态有关，且存在超长范围的高频寻路，缓存也不合适
      
        5. 分级思想，分块寻路：(❓练手)
           > 还是全图寻路，**用大的单位的联通性代替**Tile的大方向连通性(不是最短)，问题是大节点得能指导Tile，当有Tile的权重会影响走势的时候这个思路不适用    
           > 大单位是每个Hex内的极大联通分量，在没有出现分割一个Hex内的全连通性的时候，每个Hex节点就是一个大单位  
           > 如果动态阻挡改变导致Hex全连通分割比如变成两个联通分量，那么原先的Hex节点拆分为多个节点重新评估大节点之间的联通关系  
           > 用大单位节点的连通性，指导Tile的全连通寻路，即每更新一个大单位节点的联通，就限制大单位内部的Tile为当前寻路集合  
           > 全图寻路的特点是每一个最优都是基于起点，但推进寻路却不需要追溯到起点因为起点的信息已经在边缘的节点身上集成了(边缘构成openlist，在这些openlist中找最小)  
           > 动态改变就更新对应有改变的大节点(找到对应的极大联通分量，重新算联通性看有没有大单位分裂)，然后对新的节点情况进行联通更新(如果大节点有分割或者合并，则新大节点只会与原大节点的直接相邻有关系，这是更新规模上限)，将直接改变的当事大结点(不管有没有分割联通分量)，和其他被波及到而与原来连通图有差异的大节点统计起来，收集里面的的Tile与没有变化的Tile的交界线上的集合，这些集合就是openList，从这些集合继续推演所有变更的tile(相当于复用了之前的大部分结果，平行推演另一个部分差异的图)

  - 战斗
    1. 特效资源异步加载，根据模型加载情况查找依赖来异步预加载，但不需要马上使用
    2. 模型对象池预加载
    3. 中间动态数据的缓存，寻路数据
 
- 内存泄漏实例：
  - 频繁创建纹理对象然后释放旧对象，释放是异步的导致释放的没有创建的快，最终内存增长到闪退
    > 小地图是纹理绘制的，频繁切换图层的时候频繁增删
    > 报错推送定位到内存，代码调试再看vs内存增长曲线，写样例复现

  - 地图生成后内存泄漏：
    > 循环引用没有弱引用

    
#### 排查手段：
- 性能分析：用工具量化性能，抓大头，定位
  1. tracy，cprofile找性能热点：（CPU）
  2. 用render/GPA看渲染过程详情，是否面数过多，哪些是批处理了哪些断批，是否有重复渲染无效渲染(剔除)：（GPU）

- 内存泄漏：
  1. 最主要是锁定内存增长点，粗暴的可以观察任务管理器内存增长与业务逻辑的关联缩小范围
  2. 工具打印或者注释代码缩小范围，然后定位到对象后用objgraph画引用关系
  3. gc.collect()/get_objects(); tracemalloc; objgraph; pympler; mem_profiler;
     
#### 常见处理：
  - 对象池
  - 异步加载
  - 分帧
  - 缓存
  - 剪枝减循环
  - 分级(局部性原理)
  - 多线程
  - c拓展
  - 降DC
  - 减精度/面
  - lod

---
#### 重点理解概念：
##### 图集，合图，合批，断批原因  
1. 数据流向：应用业务逻辑-> 引擎 -> GPU绘制：最上层的绘制指令不是直接指导绘制，一般是以命令的形式给引擎，引擎会进行处理(cocos/u3d，相当于上层交付给openGL的Obj列表进行绘制)后再交付GPU，这里处理空间就可以支持**动态合批**处理，所以批处理的关键是引擎的这个中间操作阶段的支持    
2. 引擎的这个操作空间操作的数据：顶点(pos，uv...)，纹理，材质(包含shader，一些渲染状态)，MVC矩阵(每个obj的空间变换)，(一些贴图如法线norm??)  
3. 合批：指**shader，渲染状态相同的情况下**，差异点在**vertex*MVC**和**Texture**这两个方面，每一个obj都有自己的一套，那在不同程度上吧这些obj的这些数据合并凑成一个obj只进行一次渲染流程的过程  
4. 所以合批节约DC主要性能优化点在于节约为不同Obj都做一遍的渲染前数据准备过程，是CPU的准备运算消耗和CPU到GPU的传输消耗(不是节约GPU时间)  
5. 合批：  
   - 离线/静态合批：一些几乎不更新的静态模型(场景，场景上的装饰物)在**正式游戏循环开始**之前就按他们的世界空间分布打包成一个大网格，达成合并**Vertex * MVC**的作用，一般这里也伴随着这些合并Obj的纹理的合图  
     > 1. 离线是在游戏外部，用其他工具给完成这一步交付给开发者，静态合批是指在u3d中提供了自动合批工具会自动打包为一个大网格和生成为文件，与离线相比就是这个资产生成过程自动化了  
     > 2. 离线/静态合批的问题是内存变大，特别是有共享网格的情况下共享的网格会被n倍放大  
     > 3. 合批条件(**断批因素**)：shader一致，网格空间关系不再变化  
     > 4. U3d的静态合批实际不减少DC还是一个一个draw的只是省去状态切换❓❓  

   - 动态合批：收集Obj的时候进行统计对比，发现连续Ojb有Shader+渲染状态不变的情况就进行**收集**，然后在这个状态改变之前将收集到的一批Obj进行**Vertex * MVC**的操作，差别是这个合并网格是引擎动态做的
     > 1. 动态合批限制(**断批原因**)比较多：有顶点上限900(不管分类，如果分类为Norm/UV1/UV2还要在成倍减少)  
     > 2. Shader动态改变  
     > 3. 网格不能缩放  
     > 4. 多shader不行❓    
     > 5. 延迟渲染不行❓  
     > 6. lightMap不同不行❓  
6. 合图：
   - UI对象顶点是相对固定的Rect，差别在**MVC** 和 **纹理**上  
   - 在前文引擎支持**动态合批的基础**结构上(对比/收集Obj), 一个UI的多个子节点Obj的网格会被计算MVC合并为一个网格(只不过这个网格的顶点都在一个平面上有点不习惯)  
   - 与动态合批的差别就是UI的纹理比较小且比较多(OpenGL的纹理Sampler好像是有上限的应该会轻松超过)，所以吧纹理合成一个大纹理就能解决这个问题  
   - 对应的产物就是图集，图集也不是随便合和越大越好(一般是一张1024*1024)，吧会一起出现的纹理合在一起，如果一个批处理中依赖纹理不再一个合图中，可能会引入多个图集(但可能不会断批❓)  
     > 合图是在UI这个场景下合批的一个数据支持要求,算是动态合批的一个子集    
         
##### 压缩纹理格式  
https://zhuanlan.zhihu.com/p/237940807  
1. 无压缩格式：RGBA8888， R5G6B5等是可以直接给GPU使用，但无压缩带来存储容量问题，内存问题，传输发热问题  

2. 压缩纹理几个指标：  
  - 定速解码/不定速解码(定长编码？)  
  - 有损/无损  
  - 压缩比  
  - 解压速度(压缩一般不管)    

3. 压缩格式JPG， PNG：不支持随机访问，压缩是压缩了但GPU不好处理数据

4. 常见纹理格式：ETC(移动安卓)，BC(Window)，PVRTC(IOS)，ASTC(新协议)
   - ETC：
     > 大致算法，4*4为一个块，每个块压缩为 一个基色(R4G4B4) +   
     > 一个四分量的颜色偏移空间索引值构成的候选表(idx0, idx1, idx2, idx3)，3bit*4，每个三位的颜色偏移空间有8中偏移方案，但没个快只抽4种作为候选 +  
     > 16个2位选择器，每个选择器的取值范围0-3对应上述的候选方案编号，16个对应了4*4=16个像素组成的块  
     > 大致算法就是 基色 + 偏移候选方案空间 + 16个候选空间选择器  
     > ETC1压缩比6：1不支持A通道(原先一个块16个RGB(16*3Byte)压缩为64bit(8Byte))， ETC2支持Alpha压缩比4：1

   - BC(n):
     > 大致算法也是块算法，两个基色+16个选择器
     > BC1压缩比6：1或者1bit透明读的时候小于6：1，BC2支持Alpha压缩比4：1，后续都是4：1，还有一些预乘(❓)差别

   - PVRTC:
     > 不一样的算法，两个缩小四倍低频图双线性差值进行放大+一个全分辨率低精度权重图混合
     > 压缩比在RGBA PVRTC上可以达到8：1，RGB的是6：1

   - ASTC：
     > 算法类似BC7，也是块算法
     > 跨平台
     > 压缩比跨度大 3：1到27：1


---
#### Unity性能优化篇：
https://wetest.qq.com/labs/315  
https://zhuanlan.zhihu.com/p/364785849  
